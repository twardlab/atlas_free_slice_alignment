{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec43350a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Goal\n",
    "\n",
    "In this version I will try to parallelize things over slices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea6e10",
   "metadata": {},
   "source": [
    "# for andrew\n",
    "As before the goal is\n",
    "\n",
    "1. Create another .py file that can be imported\n",
    "1. put all the functions here into the .py file\n",
    "1. For each function add a skeleton for documentation\n",
    "1. Add a main function and a command line linterface\n",
    "1. Set up github and sphynx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5ef25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.concatenate=torch.cat # compatibility\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from os.path import join,basename,splitext\n",
    "%matplotlib widget\n",
    "from scipy.interpolate import interpn\n",
    "plt.set_loglevel('critical')\n",
    "# from scipy.misc import derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe20ce5",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_from_n_d(n,d):\n",
    "    '''\n",
    "    This function takes in an image size and pixel size, and outputs a zero centered coordinate system\n",
    "    '''\n",
    "    x = [torch.arange(ni)*di - (ni-1)*di/2 for ni,di in zip(n,d)]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extent_from_x(x):\n",
    "    '''This function gets a coordinate system and output the extent argument for matplotlib imshow'''\n",
    "    d = [xi[1]-xi[0] for xi in x]\n",
    "    return (x[1][0]-d[1]/2, x[1][-1]+d[1]/2, x[0][-1]+d[0]/2, x[0][0]-d[0]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d4dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down2ax(I,ax):\n",
    "    ndims = I.ndim\n",
    "    s0 = [slice(None) for i in range(ndims)]\n",
    "    s1 = [slice(None) for i in range(ndims)]\n",
    "    n = I.shape[ax]\n",
    "    nd = n//2\n",
    "    \n",
    "    s0[ax] = slice(0,nd*2,2)\n",
    "    s1[ax] = slice(1,nd*2,2)\n",
    "    Id = I[tuple(s0)]*0.5 + I[tuple(s1)]*0.5\n",
    "    return Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7ea399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down2(I,ax):\n",
    "    for a in ax:\n",
    "        I = down2ax(I,a)\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d734b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we have a list of files, these should be an input.\n",
    "# this example is the moon observed from a telescope.  \n",
    "# due to the atmosphere the moon looks \"wiggly\" from frame to frame, and we try to straighten out the wiggles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filesmoon=['frame_1_delay-0.2s[1].png','frame_0_delay-0.2s[1].png','frame_0_delay-0.2s[1].png','frame_1_delay-0.2s[1].png','frame_2_delay-0.2s[1].png','frame_3_delay-0.2s[1].png','frame_4_delay-0.2s[1].png','frame_5_delay-0.2s[1].png','frame_6_delay-0.2s[1].png','frame_7_delay-0.2s[1].png','frame_7_delay-0.2s[1].png','frame_6_delay-0.2s[1].png']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca6ab2",
   "metadata": {},
   "source": [
    "# Get some files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e77ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# something weird here to load the files\n",
    "# andrew, try to make it less weird\n",
    "\n",
    "import os\n",
    "img_dir = '/home/abenneck/Desktop/atlas_free_slice_alignment/images/'\n",
    "\n",
    "Nfiles=12\n",
    "#root = '/home/dtward/mounts/bmaproot/nafs/dtward/mitra_data/787_nissl_good_png/'\n",
    "#root = '/nafs/dtward/mitra_data/787_nissl_good_png/'\n",
    "#root = '/Users/12032/Downloads/mouse brain slice data'\n",
    "#files = glob(join(root,'*.png'))\n",
    "def key(f):\n",
    "    return int( splitext(basename(f))[0].split('_')[-1] )\n",
    "#files.sort(key=key)\n",
    "n = len(filesmoon)\n",
    "files = filesmoon[n//2-Nfiles//2 : n//2-Nfiles//2 + Nfiles]\n",
    "\n",
    "#fig,ax = plt.subplots(1,2)\n",
    "fig,ax = plt.subplots()\n",
    "hfig = display(fig,display_id=True)\n",
    "J_ = []\n",
    "W_ = []\n",
    "\n",
    "for i in range(Nfiles):\n",
    "    Ji = plt.imread(os.path.join(img_dir,files[i]))\n",
    "    \n",
    "    if Ji.dtype == np.uint8:\n",
    "        Ji = Ji / 255.0\n",
    "    if Ji.shape[-1] == 4:\n",
    "        Ji = Ji[...,:3]\n",
    "    \n",
    "    # find any rows or colums that are all ones\n",
    "    if Ji.ndim == 2:\n",
    "        Ji = Ji[...,None].repeat(3,axis=-1)\n",
    "    rowones = np.all(Ji>=0.95,(0,-1))\n",
    "    colones = np.all(Ji>=0.95,(1,-1))\n",
    "    Wi = (1-rowones[None,:])*(1-colones[:,None])\n",
    "    \n",
    "\n",
    "    down = 1\n",
    "    \n",
    "    ax.cla()\n",
    "    ax.imshow(Ji)\n",
    "    #ax[0].cla()\n",
    "    #ax[0].imshow(Ji)\n",
    "    #ax[1].cla()\n",
    "    #ax[1].imshow(Wi)\n",
    "    hfig.update(fig)\n",
    "    J_.append(Ji)\n",
    "    W_.append(Wi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49eeb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, every image is interpolated onto a grid of the same size\n",
    "nJ = [Ji.shape for Ji in J_]\n",
    "nJ = np.max(nJ,0)\n",
    "nJ = [len(J_),nJ[0],nJ[1]]\n",
    "x2d = [np.arange(n)*down - (n-1)*down/2 for n in nJ[1:]]\n",
    "X2d = np.stack(np.meshgrid(*x2d,indexing='ij'),-1)\n",
    "fig,ax = plt.subplots()\n",
    "hfig = display(fig,display_id=True)\n",
    "J__ = []\n",
    "W__ = []\n",
    "for Ji,Wi in zip(J_,W_):\n",
    "    x = [np.arange(n)*down - (n-1)*down/2 for n in Ji.shape[:2]]\n",
    "    Ji_ = interpn(x,Ji,X2d,bounds_error=False,method='nearest')\n",
    "    Wi_ = interpn(x,Wi,X2d,bounds_error=False,method='nearest')\n",
    "    \n",
    "    Wi_ = (1.0 - np.isnan(Ji_[...,0]))*Wi_\n",
    "    Ji_[np.isnan(Ji_)] = 0\n",
    "    Wi_[np.isnan(Wi_)] = 0\n",
    "    J__.append(Ji_)\n",
    "    W__.append(Wi_)\n",
    "    ax.cla()\n",
    "    ax.imshow(Ji_)\n",
    "    hfig.update(fig)\n",
    "\n",
    "# note our convention is to use \n",
    "print([ji.shape for ji in J_])\n",
    "print([wi.shape for wi in W_])\n",
    "J = np.stack(J__,0).transpose(-1,0,1,2)\n",
    "W = np.stack(W__)\n",
    "xJ = [np.arange(nJ[0])-(nJ[0]-1)/2,x2d[0],x2d[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af42eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad\n",
    "# optionally, we may pad the first and last slice.  This is related to FFT for bluring and circular correlatoins.\n",
    "# this padding parameter will have to be exposed\n",
    "npad = 0\n",
    "J = np.pad(J,((0,0),(npad,npad),(0,0),(0,0)),mode='reflect')\n",
    "W = np.pad(W,((npad,npad),(0,0),(0,0)),mode='reflect')\n",
    "nJ = J.shape[1:]\n",
    "xJ = [np.arange(nJ[0])-(nJ[0]-1)/2,x2d[0],x2d[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d6e08",
   "metadata": {},
   "source": [
    "# Convert to pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "dtype = torch.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895ea600",
   "metadata": {},
   "outputs": [],
   "source": [
    "J = torch.tensor(J,dtype=dtype,device=device)\n",
    "W = torch.tensor(W,dtype=dtype,device=device)\n",
    "xJ = [torch.tensor(x,dtype=dtype,device=device) for x in xJ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e633b701",
   "metadata": {},
   "source": [
    "# Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d0a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp(x,I,phii,**kwargs):\n",
    "    '''\n",
    "    Interpolate a signal with specified voxel spacing, in torch.    \n",
    "    \n",
    "    Input data should be 3D images, with first dimension a channel.\n",
    "    \n",
    "    phii has xyz on LAST dimension.\n",
    "    \n",
    "    What if there's only one slice? \n",
    "    '''\n",
    "    # first we center phii based on x\n",
    "    x0 = torch.stack([xi[0] for xi in x])\n",
    "    d = torch.stack([xi[-1] - xi[0] for xi in x]) # this will fail if there's only one slice\n",
    "    phii = (phii - x0)/d*2-1\n",
    "    \n",
    "    if 'align_corners' not in kwargs:\n",
    "        kwargs['align_corners'] = True\n",
    "    \n",
    "    phiI = torch.nn.functional.grid_sample(I[None],phii.flip(-1)[None],**kwargs)[0]\n",
    "    return phiI\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174c17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def A2DtoA3D(A):\n",
    "    row = torch.concatenate( (torch.ones_like(A[:,0,0,None,None]) , torch.zeros_like(A[:,0,None])  ),-1)\n",
    "    col = torch.zeros_like(A[:,:,0,None])\n",
    "    \n",
    "    colA = torch.concatenate([col,A],-1)\n",
    "    \n",
    "    return torch.concatenate([row,colA],-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7659df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to apply a linear transform I need a sequence of 2D affine matrices\n",
    "XJ = torch.stack(torch.meshgrid(xJ,indexing='ij'),-1)\n",
    "A = torch.eye(3)\n",
    "A[0,0] = 1.1\n",
    "A[1,1] = 0.9\n",
    "A = A[None].repeat(nJ[0],1,1)\n",
    "A = A2DtoA3D(A)\n",
    "Ai = torch.linalg.inv(A)\n",
    "# another function that can be imported\n",
    "def AX(Ai,XJ):    \n",
    "    Xs = (Ai[:,None,None,:3,:3]@XJ[...,None])[...,0] + Ai[:,None,None,:3,-1]\n",
    "    return Xs\n",
    "Xs = AX(Ai,XJ)\n",
    "# first test identity\n",
    "AJ = interp(xJ,J,XJ)\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(J[:,AJ.shape[1]//2].permute(1,2,0))\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(AJ[:,AJ.shape[1]//2].permute(1,2,0))\n",
    "AJ = interp(xJ,J,Xs)\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(AJ[:,AJ.shape[1]//2].permute(1,2,0))\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(AJ[:,:,AJ.shape[2]//2].permute(1,2,0),aspect='auto')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a24b70",
   "metadata": {},
   "source": [
    "# Group exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a26e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp(x,v,N=5):\n",
    "    '''\n",
    "    Group exponential by scaling and squaring\n",
    "    v should have xyz components at the end and be 3d\n",
    "    \n",
    "    Take a small displacement, and compose it with itself \n",
    "    many times, to give a big displacement.\n",
    "    \n",
    "    If N = 1, the output is id + v\n",
    "    \n",
    "    If N = 2, the output is (id + v/2)\\circ (id + v/2)\n",
    "    \n",
    "    If N = 3, the output is (id + v/8)\\circ ... \\circ (id + v/8)\n",
    "    '''\n",
    "    X = torch.stack(torch.meshgrid(*x,indexing='ij'),-1)\n",
    "    phi = X.clone() + v / 2**N\n",
    "    for i in range(N-1):\n",
    "        # when interpolating, move xyz component to the beginning, then back\n",
    "        # 0 boundary conditions are probably ok\n",
    "        phi = interp(x,(phi-X).permute(-1,0,1,2),phi).permute(1,2,3,0) + phi\n",
    "    \n",
    "    return phi\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1cd0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test it\n",
    "# get a set of sample points for v\n",
    "extendv = 1.1 # i.e. make it 10% bigger than the domain of J, to avoid wraparound\n",
    "dv = down*2\n",
    "vmin1 = torch.amin(xJ[1])\n",
    "vmin2 = torch.amin(xJ[2])\n",
    "vmax1 = torch.amax(xJ[1])\n",
    "vmax2 = torch.amax(xJ[2])\n",
    "vc1 = (vmin1 + vmax1)/2\n",
    "vc2 = (vmin2 + vmax2)/2\n",
    "vr1 = (vmax1-vmin1)/2*extendv\n",
    "vr2 = (vmax2-vmin2)/2*extendv\n",
    "v1 = torch.arange(vc1-vr1,vc1+vr1,dv,device=device,dtype=dtype)\n",
    "v2 = torch.arange(vc2-vr2,vc2+vr2,dv,device=device,dtype=dtype)\n",
    "xv = [xJ[0],v1,v2]\n",
    "XV = torch.stack( torch.meshgrid(*xv,indexing='ij') , -1)\n",
    "XV2d = XV[...,1:]\n",
    "v2d = torch.zeros_like(XV2d) \n",
    "v2d = torch.randn(v2d.shape,dtype=v2d.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c630f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get highpass and lowpass operators for 2d reg\n",
    "a = 10.0\n",
    "p = 2.0\n",
    "\n",
    "def L_from_xv_a_p(xv,a,p):\n",
    "    dv = xv[-1][1] - xv[-1][0]\n",
    "    fv = [torch.arange(n)/n/dv for n in (len(xv[-2]), len(xv[-1]))]\n",
    "    FV = torch.stack(torch.meshgrid(fv,indexing='ij'),-1)\n",
    "    L = (1.0 - torch.sum(2.0*a**2*(torch.cos(2.0*np.pi*FV*dv) - 1)/dv,-1))**p\n",
    "    return L\n",
    "L = L_from_xv_a_p(xv,a,p)\n",
    "LL = L**2\n",
    "K = 1.0/LL\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(L)\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2d = torch.fft.ifftn( torch.fft.fftn(v2d,dim=(1,2))*K[...,None] , dim=(1,2),).real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4a2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to convert v2d to v3d\n",
    "def v2DToV3D(v2d):\n",
    "    return torch.concatenate( ( torch.zeros_like(v2d[...,0,None]), v2d ) , -1)\n",
    "v3d = v2DToV3D(v2d)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3532874",
   "metadata": {},
   "outputs": [],
   "source": [
    "v3d /= torch.std(v3d)\n",
    "v3d *= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215569ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = v2d # for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d6711",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = exp(xv,v3d)\n",
    "fig,ax = plt.subplots()\n",
    "ax.contour(xv[2],xv[1],phi[phi.shape[0]//2,...,1])\n",
    "ax.contour(xv[2],xv[1],phi[phi.shape[0]//2,...,2])\n",
    "ax.set_title('Example deformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78cff17",
   "metadata": {},
   "source": [
    "# Weighted SSE registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9cd04d",
   "metadata": {},
   "source": [
    "inputs are\n",
    "\n",
    "I,xI\n",
    "J,xJ\n",
    "W\n",
    "\n",
    "v,xv \n",
    "\n",
    "A\n",
    "\n",
    "a\n",
    "p\n",
    "\n",
    "ep\n",
    "\n",
    "sigmaM\n",
    "sigmaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CONTINUE CONVERTING NOTEBOOK INTO SCRIPTS\n",
    "\n",
    "# initial guess\n",
    "I = (torch.sum(J*W,1,keepdims=True)/(1e-6 + torch.sum(W,0,keepdims=True))).repeat(1,J.shape[1],1,1)\n",
    "xI = [x.clone() for x in xJ]\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(I[:,I.shape[1]//2].permute(1,2,0))\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(I[:,:,I.shape[2]//2].permute(1,2,0),aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b3fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform an image with phi\n",
    "phiI = interp(xI,I,phi)\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(phiI[:,AJ.shape[1]//2].permute(1,2,0))\n",
    "\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(phiI[:,:,phiI.shape[2]//2].permute(1,2,0),aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f73ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(xI,I,xv,v,A,xJ,**kwargs):\n",
    "    ''' Note this is redundant with the below, but is a nice helper function'''\n",
    "    XJ = torch.stack(torch.meshgrid(*xJ,indexing='ij'),-1)\n",
    "    XV = torch.stack(torch.meshgrid(*xv,indexing='ij'),-1)\n",
    "    \n",
    "    Ai = torch.linalg.inv(A)\n",
    "    Ai = A2DtoA3D(Ai)\n",
    "    Xs = AX(Ai,XJ)\n",
    "\n",
    "    # convert v to phii\n",
    "    phii = exp(xv,v2DToV3D(-v))\n",
    "\n",
    "    # sample at Xs\n",
    "    Xs = interp(xv,(phii - XV).permute(-1,0,1,2), Xs).permute(1,2,3,0) + Xs\n",
    "\n",
    "    # transform the image\n",
    "    if 'padding_mode' not in kwargs:\n",
    "        kwargs['padding_mode'] = 'border'\n",
    "    AphiI = interp(xI,I,Xs,**kwargs)\n",
    "\n",
    "    return AphiI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_image(xI,I,xv,v,A,xJ,**kwargs):\n",
    "    ''' Note this is redundant with the below, but is a nice helper function'''\n",
    "    XJ = torch.stack(torch.meshgrid(*xJ,indexing='ij'),-1)\n",
    "    XV = torch.stack(torch.meshgrid(*xv,indexing='ij'),-1)\n",
    "    \n",
    "    \n",
    "    A = A2DtoA3D(A)\n",
    "    \n",
    "\n",
    "    # convert v to phii\n",
    "    phi = exp(xv,v2DToV3D(v))\n",
    "    \n",
    "    # sample on xj\n",
    "    phis = interp(xv,(phi-XV).permute(-1,0,1,2),XJ).permute(1,2,3,0) + XJ\n",
    "    \n",
    "    Xs = AX(A,phis)\n",
    "        \n",
    "    # transform the image\n",
    "    if 'padding_mode' not in kwargs:\n",
    "        kwargs['padding_mode'] = 'border'\n",
    "    phiiAiI = interp(xI,I,Xs,**kwargs)\n",
    "\n",
    "    return phiiAiI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# andrew use this one, not the commented ones below\n",
    "def weighted_see_registration(xI,I,xJ,J,W,xv,v,A,a,p,sigmaM,sigmaR,niter,epT,epL,epv,draw=0,fig=None,hfig=None):\n",
    "\n",
    "    A.requires_grad = True\n",
    "    v.requires_grad = True\n",
    "\n",
    "    XJ = torch.stack(torch.meshgrid(*xJ,indexing='ij'),-1)\n",
    "    XV = torch.stack(torch.meshgrid(*xv,indexing='ij'),-1)\n",
    "    dv = torch.stack([x[1] - x[0] for x in xv])\n",
    "    Dv = torch.prod(dv)\n",
    "    dJ = torch.stack([x[1] - x[0] for x in xJ])\n",
    "    DJ = torch.prod(dJ)\n",
    "    L = L_from_xv_a_p(xv,a,p)\n",
    "    LL = L**2\n",
    "    K = 1.0/LL\n",
    "\n",
    "    Esave = []\n",
    "    Tsave = []\n",
    "    Lsave = []\n",
    "    maxvsave = []\n",
    "    if draw:\n",
    "        if fig is None:\n",
    "            fig,ax = plt.subplots(2,3)\n",
    "            ax = ax.ravel()\n",
    "        else:\n",
    "            fig.clf()\n",
    "            ax = []\n",
    "            for i in range(2):\n",
    "                for j in range(3):\n",
    "                    ax.append(fig.add_subplot(2,3,i*3+j+1))\n",
    "        if hfig is None:\n",
    "            hfig = display(fig,display_id=True)\n",
    "    for it in range(niter):\n",
    "        if v.grad is not None:\n",
    "            v.grad.zero_()\n",
    "        if A.grad is not None:\n",
    "            A.grad.zero_()\n",
    "        # act on XJ\n",
    "        Ai = torch.linalg.inv(A)\n",
    "        Ai = A2DtoA3D(Ai)\n",
    "        Xs = AX(Ai,XJ)\n",
    "\n",
    "        # convert v to phii\n",
    "        phii = exp(xv,v2DToV3D(-v))\n",
    "\n",
    "        # sample at Xs\n",
    "        Xs = interp(xv,(phii - XV).permute(-1,0,1,2), Xs).permute(1,2,3,0) + Xs\n",
    "\n",
    "        # transform the image\n",
    "        AphiI = interp(xI,I,Xs,padding_mode='border') # border boundary condition is important when we have a white background\n",
    "\n",
    "        # get error\n",
    "        EM = torch.sum((AphiI - J)**2*W)*DJ/sigmaM**2/2.0\n",
    "        ER = torch.sum(torch.sum( torch.abs( torch.fft.fftn(v,dim=(1,2)) )**2 , -1)*LL)/sigmaR**2/2.0/v[0,...,0].numel()*Dv\n",
    "        E = EM + ER\n",
    "        Esave.append([E.item(),EM.item(),ER.item()])\n",
    "        Tsave.append(    A[:,:2,-1].clone().detach().cpu().ravel().numpy()  )\n",
    "        Lsave.append( A[:,:2,:2].clone().detach().cpu().ravel().numpy()    )\n",
    "        maxvsave.append(  (torch.amax(torch.sum(v.clone().detach()**2,-1))**0.5).cpu().numpy().item()  )\n",
    "        # backprop\n",
    "        E.backward()\n",
    "\n",
    "        # update\n",
    "        with torch.no_grad():\n",
    "            # update T\n",
    "            A[:,:2,-1] -= A.grad[:,:2,-1]*epT\n",
    "            # update L\n",
    "            A[:,:2,:2] -= A.grad[:,:2,:2]*epL\n",
    "            # rigid\n",
    "            u,s,vh = torch.linalg.svd(A[:,:2,:2])\n",
    "            A[:,:2,:2] = u@vh\n",
    "\n",
    "\n",
    "            # update v\n",
    "            v[:] = v[:] - torch.fft.ifftn(torch.fft.fftn(v.grad,dim=(1,2))*K[...,None],dim=(1,2)).real*epv\n",
    "\n",
    "        # draw\n",
    "        with torch.no_grad():\n",
    "            if draw and (not it%draw or it == niter-1):\n",
    "                ax[0].cla()\n",
    "                ax[0].plot(Esave)\n",
    "                ax[0].set_title('energy')\n",
    "                ax[1].cla()\n",
    "                ax[1].plot(Tsave)\n",
    "                ax[1].set_title('Translation')\n",
    "                ax[2].cla()\n",
    "                ax[2].plot(Lsave)\n",
    "                ax[2].set_title('Linear')\n",
    "                ax[3].cla()\n",
    "                ax[3].plot(maxvsave)\n",
    "                ax[3].set_title('max |v|')\n",
    "                \n",
    "                \n",
    "                ax[4].cla()\n",
    "                ax[4].imshow(  ( (AphiI[:,:,J.shape[2]//2]-J[:,:,J.shape[2]//2])*W[:,J.shape[2]//2]  ).permute(1,2,0).cpu()*0.5+0.5  ,aspect='auto', interpolation='none')\n",
    "                #ax[5].cla()\n",
    "                #ax[5].imshow(  (  (AphiI[:,:,:,J.shape[3]//2]-J[:,:,:,J.shape[3]//2])*W[:,:,J.shape[3]//2] ).permute(1,2,0).cpu()*0.5+0.5  ,aspect='auto', interpolation='none')\n",
    "                \n",
    "                ax[5].cla()\n",
    "                ax[5].imshow(  (  (AphiI[:,:,:,J.shape[3]//2]-J[:,:,:,J.shape[3]//2])*W[:,:,J.shape[3]//2] ).permute(1,2,0).cpu()*0.5+0.5  ,aspect='auto', interpolation='none')\n",
    "\n",
    "                hfig.update(fig)\n",
    "\n",
    "    A.requires_grad = False\n",
    "    v.requires_grad = False\n",
    "    \n",
    "    return A,v,E.item(),ER.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98906a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is just a test, it is not necessary in our code\n",
    "A = torch.eye(3)[None].repeat(J.shape[1],1,1)\n",
    "v = torch.zeros_like(v)\n",
    "\n",
    "niter = 2\n",
    "niter = 1\n",
    "niter = 10\n",
    "epT = 1e-2\n",
    "epL = 1e-6\n",
    "epv = 1e1\n",
    "sigmaM = 1.0 # this should always be 1\n",
    "sigmaR = 1e5\n",
    "draw = 5\n",
    "\n",
    "\n",
    "Anew,vnew,Eregistration,Ereg = weighted_see_registration(xI,I,xJ,J,W,xv,v,A,a,p,sigmaM,sigmaR,niter,epT,epL,epv,draw=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059889e7",
   "metadata": {},
   "source": [
    "# Get Jacobian weights\n",
    "We we want the forward transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d238a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detjac(xv,v):\n",
    "    dv = [(x[1] - x[0]).item() for x in xv]    \n",
    "    detjac = torch.linalg.det( torch.stack(torch.gradient( exp(xv,v2DToV3D(v))[...,1:] , dim=(1,2),spacing=(dv[1],dv[2])),-1) )\n",
    "    return detjac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f122b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wdetjac = detjac(xv,vnew)\n",
    "fig,ax = plt.subplots()\n",
    "mappable = ax.imshow(Wdetjac[Wdetjac.shape[0]//2])\n",
    "plt.colorbar(mappable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa6b5d",
   "metadata": {},
   "source": [
    "# Get robustness loss and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d957dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_loss(RphiI,xJ,J,W,c, return_weights=False):\n",
    "    ''' we input the deformed atlas I, the target J, and the voxel coordinates of J, and the robust constant c\n",
    "    note there is a W here which should be binary because we're not going to sum over all the pixels\n",
    "    \n",
    "    TODO\n",
    "    ----\n",
    "    pixel size factor will show up in the weights term also\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    dxJ = torch.stack([(x[1]-x[0]) for x in xJ])\n",
    "    DJ = torch.prod(dxJ)\n",
    "    \n",
    "    err2 =  torch.sum( (RphiI - J)**2  , 0)*W # make sure the error does not go on padding\n",
    "    E = c*torch.sum(err2 / (  err2 + c )  )*DJ\n",
    "    \n",
    "    if not return_weights:\n",
    "        return E\n",
    "    else:\n",
    "        W = c**2 / ( (c + err2.clone().detach())**2 )*W # make sure weight is 0\n",
    "        # note: we do not include pixel size d here because it will get multiplied by d later\n",
    "        # no gradient calculations here\n",
    "        # note, if c is really big, this goes to 0\n",
    "        # and if c is really small, this looks like c/err2**2, and so also goes to 0\n",
    "        return E, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.imshow(W[W.shape[0]//2],interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ab54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RphiI = transform_image(xI,I,xv,vnew,Anew,xJ)\n",
    "# draw it\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(RphiI[:,:,RphiI.shape[2]//2].permute(1,2,0),aspect='auto',interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0.5\n",
    "L,WR = robust_loss(RphiI,xJ,J,W,c, return_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da37eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.imshow(WR[WR.shape[0]//2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2ac158",
   "metadata": {},
   "source": [
    "# Update atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atlas_from_aligned_slices_and_weights(xI,I,phiiRiJ,W,asquare,niter=10,draw=0,fig=None,hfig=None):\n",
    "    '''\n",
    "    Inputs are 3D pixel locations. xI\n",
    "    \n",
    "    Initial guess of atlas I.\n",
    "    \n",
    "    We previously calculated RphiI, and we need the oppose. We need phiiRiJ\n",
    "    \n",
    "    a coefficient in front of laplacian.  This has units of length, so we have asquare \\Delta\n",
    "    \n",
    "    we want to minimize\n",
    "    \n",
    "    note, W needs to include determinant of jacobians\n",
    "    \n",
    "    \\int \\|I - phiiRiJ\\|**2 W dx + \\int |L  I|**2 dx\n",
    "    \n",
    "    Here L will be a negative laplacian\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if draw:\n",
    "        if fig is None:\n",
    "            fig = plt.figure()\n",
    "        if hfig is None:\n",
    "            hfig = display(fig,display_id=True)\n",
    "    \n",
    "    # we don't want to propagate gradients here\n",
    "    phiiRiJ = phiiRiJ.clone().detach()\n",
    "    I = I.clone().detach()    \n",
    "    W = W.clone().detach()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # normalize W\n",
    "    Wm = torch.max(W)\n",
    "    Wn = W/Wm\n",
    "\n",
    "     # make a Fourier domain\n",
    "    n = len(xI[0])\n",
    "    dI = torch.stack([x[1] - x[0] for x in xI])\n",
    "    DI = torch.prod(dI)\n",
    "    #d = dI[0]\n",
    "    # we use the convention that slices are one unit apart\n",
    "    d=1\n",
    "    f = torch.arange(n,dtype=dtype,device=device)/n/d\n",
    "        \n",
    "  \n",
    "    \n",
    "    \n",
    "    # define the operator in the fourier domain\n",
    "    # LL plus identity\n",
    "    L = (2.0*asquare* (1-torch.cos(2.0*np.pi*f*d))/d**2)\n",
    "    LL = L**2\n",
    "    LLnorm=LL/Wm\n",
    "    oooperator = 1.0 / (1.0 + LLnorm)   \n",
    "    Esave = []\n",
    "\n",
    "            \n",
    "    ERsave = []\n",
    "    EMsave = []\n",
    "    Esave = []\n",
    "    for it in range(niter):\n",
    "        # value of the loss\n",
    "        ER = torch.sum( torch.fft.ifftn( torch.fft.fftn(I,dim=1)*L[...,None,None] , dim=1).real**2 )*DI\n",
    "        #print('Ishape is',I.shape)\n",
    "        #print('phiiRiJ shape is',phiiRiJ.shape)\n",
    "        #print('W shape is',W.shape)\n",
    "        #EMM = torch.sum(  (I - phiiRiJ)**2 * W )/2*DI*Wm\n",
    "        #EM = torch.sum(   ((I-phiiRiJ)**2/(c + (I-phiiRiJ)**2))   )*DI # middle term of 2.12\n",
    "        EM = torch.sum( (I-phiiRiJ)**2*W)*DI # daniel changed this\n",
    "        E = ER + EM\n",
    "        Esave.append(E.item())\n",
    "        ERsave.append(ER.item())\n",
    "        EMsave.append(EM.item())\n",
    "        \n",
    "        # update\n",
    "        toblur = ( phiiRiJ*Wn + I*(1-Wn) )\n",
    "        blurred = torch.fft.ifftn(torch.fft.fftn(toblur,dim=1)*oooperator[...,None,None],dim=1).real\n",
    "        I = blurred\n",
    "        \n",
    "        if draw and (not it%draw or it == niter-1):\n",
    "            fig.clf()\n",
    "            ax = fig.add_subplot(2,3,1)\n",
    "            ax.imshow(I[:,I.shape[1]//2].permute(1,2,0))\n",
    "            ax = fig.add_subplot(2,3,2)\n",
    "            ax.imshow(I[:,:,I.shape[2]//2].permute(1,2,0),interpolation='none',aspect='auto')\n",
    "            ax = fig.add_subplot(2,3,3)\n",
    "            ax.imshow(I[:,:,:,I.shape[3]//2].permute(1,2,0),interpolation='none',aspect='auto')\n",
    "            \n",
    "            ax = fig.add_subplot(2,3,4)\n",
    "            ax.imshow(phiiRiJ[:,I.shape[1]//2].permute(1,2,0))\n",
    "            ax = fig.add_subplot(2,3,5)\n",
    "            ax.imshow(phiiRiJ[:,:,I.shape[2]//2].permute(1,2,0),interpolation='none',aspect='auto')\n",
    "            ax = fig.add_subplot(2,3,6)\n",
    "            ax.imshow(phiiRiJ[:,:,:,I.shape[3]//2].permute(1,2,0),interpolation='none',aspect='auto')\n",
    "            hfig.update(fig)\n",
    "        \n",
    "    \n",
    "    return I,E.item(),ER.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae99ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# andrew use this version because it does 3D blur, instead of 1d blur\n",
    "# but keep the other one somewhere and give it a modified name (like underscore at the end)\n",
    "def atlas_from_aligned_slices_and_weights(xI,I,phiiRiJ,W,asquare,niter=10,draw=0,fig=None,hfig=None,anisotropy_factor=4**2,return_K=False,return_fwhm=False):\n",
    "    '''\n",
    "    Inputs are 3D pixel locations. xI\n",
    "    \n",
    "    Initial guess of atlas I.\n",
    "    \n",
    "    We previously calculated RphiI, and we need the oppose. We need phiiRiJ\n",
    "    \n",
    "    a coefficient in front of laplacian.  This has units of length, so we have asquare \\Delta\n",
    "    \n",
    "    we want to minimize\n",
    "    \n",
    "    note, W needs to include determinant of jacobians\n",
    "    \n",
    "    \\int \\|I - phiiRiJ\\|**2 W dx + \\int |L  I|**2 dx\n",
    "    \n",
    "    Here L will be a negative laplacian\n",
    "    \n",
    "    In this version we do bluring in 3D\n",
    "\n",
    "    TODO\n",
    "    ----\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if draw:\n",
    "        if fig is None:\n",
    "            fig = plt.figure()\n",
    "        if hfig is None:\n",
    "            hfig = display(fig,display_id=True)\n",
    "    \n",
    "    # we don't want to propagate gradients here\n",
    "    phiiRiJ = phiiRiJ.clone().detach()\n",
    "    I = I.clone().detach()    \n",
    "    W = W.clone().detach()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # normalize W\n",
    "    Wm = torch.max(W)\n",
    "    Wn = W/Wm\n",
    "\n",
    "     # make a Fourier domain\n",
    "    n = len(xI[0])\n",
    "    dI = torch.stack([x[1] - x[0] for x in xI])\n",
    "    DI = torch.prod(dI)\n",
    "    #d = dI[0]\n",
    "    # we use the convention that slices are one unit apart\n",
    "    d=1\n",
    "    #f = torch.arange(n,dtype=dtype,device=device)/n/d\n",
    "    \n",
    "    # try here to blur in 3D\n",
    "    f = [torch.arange(ni,dtype=dtype,device=device)/ni/di for ni,di in zip(I.shape[1:],dI)]\n",
    "    F = torch.stack(torch.meshgrid(*f,indexing='ij'),-1)\n",
    "    \n",
    "    \n",
    "    # define the operator in the fourier domain\n",
    "    # LL plus identity\n",
    "    #L = (2.0*asquare* (1-torch.cos(2.0*np.pi*f*d))/d**2)\n",
    "    asquare3d = torch.tensor([asquare,asquare*anisotropy_factor,asquare*anisotropy_factor],device=device,dtype=dtype)\n",
    "    L = 2.0* torch.sum( asquare3d*(1-torch.cos(2.0*np.pi*F*dI))/dI**2,-1)\n",
    "    LL = L**2\n",
    "    LLnorm=LL/Wm\n",
    "    oooperator = 1.0 / (1.0 + LLnorm)   \n",
    "    # for FWHM computation, let's take the inverse fourier transform\n",
    "    if return_fwhm or return_K:\n",
    "        K = torch.fft.ifftn(oooperator).real\n",
    "\n",
    "    Esave = []\n",
    "\n",
    "            \n",
    "    ERsave = []\n",
    "    EMsave = []\n",
    "    Esave = []\n",
    "    for it in range(niter):\n",
    "        # value of the loss\n",
    "        #ER = torch.sum( torch.fft.ifftn( torch.fft.fftn(I,dim=1)*L[...,None,None] , dim=1).real**2 )*DI\n",
    "        ER = torch.sum( torch.fft.ifftn( torch.fft.fftn(I,dim=(1,2,3))*L , dim=(1,2,3)).real**2 )*DI\n",
    "        #print('Ishape is',I.shape)\n",
    "        #print('phiiRiJ shape is',phiiRiJ.shape)\n",
    "        #print('W shape is',W.shape)\n",
    "        #EMM = torch.sum(  (I - phiiRiJ)**2 * W )/2*DI*Wm\n",
    "        #EM = torch.sum(   ((I-phiiRiJ)**2/(c + (I-phiiRiJ)**2))   )*DI # middle term of 2.12\n",
    "        EM = torch.sum( (I-phiiRiJ)**2*W)*DI # daniel changed this\n",
    "        E = ER + EM\n",
    "        Esave.append(E.item())\n",
    "        ERsave.append(ER.item())\n",
    "        EMsave.append(EM.item())\n",
    "        \n",
    "        # update\n",
    "        toblur = ( phiiRiJ*Wn + I*(1-Wn) )\n",
    "        blurred = torch.fft.ifftn(torch.fft.fftn(toblur,dim=(1,2,3))*oooperator,dim=(1,2,3)).real\n",
    "        I = blurred\n",
    "        \n",
    "        if draw and (not it%draw or it == niter-1):\n",
    "            fig.clf()\n",
    "            ax = fig.add_subplot(2,3,1)\n",
    "            ax.imshow(I[:,I.shape[1]//2].permute(1,2,0))\n",
    "            ax = fig.add_subplot(2,3,2)\n",
    "            ax.imshow(I[:,:,I.shape[2]//2].permute(1,2,0),interpolation='none',aspect='auto')\n",
    "            ax = fig.add_subplot(2,3,3)\n",
    "            ax.imshow(I[:,:,:,I.shape[3]//2].permute(1,2,0),interpolation='none',aspect='auto')\n",
    "            \n",
    "            ax = fig.add_subplot(2,3,4)\n",
    "            ax.imshow(phiiRiJ[:,I.shape[1]//2].permute(1,2,0))\n",
    "            ax = fig.add_subplot(2,3,5)\n",
    "            ax.imshow(phiiRiJ[:,:,I.shape[2]//2].permute(1,2,0),interpolation='none',aspect='auto')\n",
    "            ax = fig.add_subplot(2,3,6)\n",
    "            ax.imshow(phiiRiJ[:,:,:,I.shape[3]//2].permute(1,2,0),interpolation='none',aspect='auto')\n",
    "            hfig.update(fig)\n",
    "        \n",
    "    if return_K:\n",
    "        return K\n",
    "    elif return_fwhm:\n",
    "\n",
    "        half_width_half_max = np.where(K[:,0,0].numpy()<0.5*K[0,0,0].numpy())[0][0]\n",
    "        full_width_half_max_0 = 2*half_width_half_max+1\n",
    "        half_width_half_max = np.where(K[0,:,0].numpy()<0.5*K[0,0,0].numpy())[0][0]\n",
    "        full_width_half_max_1 = 2*half_width_half_max+1\n",
    "        half_width_half_max = np.where(K[0,0,:].numpy()<0.5*K[0,0,0].numpy())[0][0]\n",
    "        full_width_half_max_2 = 2*half_width_half_max+1\n",
    "    \n",
    "        return full_width_half_max_0,full_width_half_max_1,full_width_half_max_2\n",
    "    else: # normal returns\n",
    "        return I,E.item(),ER.item()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e189ea-8186-4b41-b0ed-0ae212c7aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "phiiRiJ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a49ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get phiiRiJ\n",
    "phiiRiJ = inverse_transform_image(xJ,J,xv,vnew,Anew,xI,padding_mode='border')\n",
    "phiiRiW = inverse_transform_image(xJ,W[None]*WR,xv,vnew,Anew,xI,padding_mode='zeros',mode='nearest')[0]\n",
    "XI = torch.stack(torch.meshgrid(xI,indexing='ij'),-1)\n",
    "Wdetjacs = interp(xv,Wdetjac[None],XI)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade0550",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.imshow((phiiRiJ)[:,I.shape[1]//2].permute(1,2,0))\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow((phiiRiW)[I.shape[1]//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inew = I.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6afa313",
   "metadata": {},
   "outputs": [],
   "source": [
    "asquare = 2.0**2\n",
    "anisotropy_factor = 1.0\n",
    "Inew,Eat,ERat = atlas_from_aligned_slices_and_weights(xI,Inew*0,phiiRiJ,phiiRiW*Wdetjacs,asquare,niter=2,draw=True,anisotropy_factor=anisotropy_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb01e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.imshow(Inew[:,I.shape[1]//2].permute(1,2,0))\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(Inew[:,:,I.shape[2]//2].permute(1,2,0),aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760652ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test the FWHM\n",
    "asquare = 3.5**2\n",
    "anisotropy_factor = 0.3**2\n",
    "fwhm = atlas_from_aligned_slices_and_weights(xI,Inew*0,phiiRiJ,phiiRiW*Wdetjacs,asquare,niter=2,draw=True,return_fwhm=True,anisotropy_factor=anisotropy_factor)\n",
    "print(fwhm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9cd80d",
   "metadata": {},
   "source": [
    "\n",
    "# now all the parts are in place, need to set up the big algorithm\n",
    "\n",
    "note for andrew.  this big algorithm seems to not be wrapped in a function.  It probably should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321597d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters\n",
    "# images\n",
    "# xJ, J, W\n",
    "# initial guess for atlas\n",
    "# xI, I\n",
    "# initial transforms\n",
    "# xv, v\n",
    "# A\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18faf149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # in this cell I only run for one iteration with no registration\n",
    "# # but I do estimate the atlas\n",
    "# # Andrew: we don't need this cell, use the one below\n",
    "# niter_big_loop = 2\n",
    "# niter_reg = 1\n",
    "# niter_atlas = 50\n",
    "# asquare = 0.25**2\n",
    "# asquare0=0.25**2\n",
    "# asquare0 = 3.5**2\n",
    "# anisotropy_factor = 0.1**2\n",
    "\n",
    "# epT = 1e-2*2*2*0\n",
    "# epL = 1e-6*2*2*0\n",
    "# epv = 1e1*2\n",
    "# epv = 1e3\n",
    "# epv = 1e2*5\n",
    "# epv = 0\n",
    "# c = 1.0 # bigger c means less robustness\n",
    "# c = 2.0\n",
    "\n",
    "# sigmaM = 1.0 # this should always be 1\n",
    "# sigmaR = 1e5 # should be smaller\n",
    "# sigmaR = 1e4\n",
    "# sigmaR = 2e2\n",
    "# sigmaR = 5e2\n",
    "# a = 8.0 # was 10\n",
    "\n",
    "\n",
    "# fig_at,ax_at = plt.subplots(2,3)\n",
    "# ax_at = ax_at.ravel()\n",
    "# hfig_at = display(fig_at,display_id=True)\n",
    "\n",
    "# fig_at_estimate = plt.figure()\n",
    "# hfig_at_estimate = display(fig_at_estimate,display_id=True)\n",
    "# fig_reg = plt.figure()\n",
    "# hfig_reg = display(fig_reg,display_id=True)\n",
    "# fig_E,ax_E = plt.subplots(1,1)\n",
    "# if isinstance(ax_E,np.ndarray):\n",
    "#     ax_E = ax_E.ravel()\n",
    "# else:\n",
    "#     ax_E = [ax_E]\n",
    "# hfig_E = display(fig_E,display_id=True)\n",
    "# # we want xI bigger than xJ so ther are no boundary issues\n",
    "# bigger = 20\n",
    "# x2dI = [torch.arange(n+bigger,dtype=dtype)*down - (n+bigger-1)*down/2 for n in nJ[1:]]\n",
    "# xI = [torch.arange(nJ[0],dtype=dtype)-(nJ[0]-1)/2,x2dI[0],x2dI[1]]\n",
    "# XI = torch.stack(torch.meshgrid(xI,indexing='ij'),-1)\n",
    "\n",
    "# # this is the loss we want to report, not WSEE loss\n",
    "# Esave = []\n",
    "# v = torch.zeros_like(v)\n",
    "# A = torch.eye(3)\n",
    "# A = A[None].repeat(nJ[0],1,1)\n",
    "\n",
    "\n",
    "# # initialize with mean\n",
    "# I = torch.zeros((J.shape[0],XI.shape[0],XI.shape[1],XI.shape[2])) + (torch.sum(J*W,dim=(1,2,3))/torch.sum(W,dim=(0,1,2)))[...,None,None,None]    \n",
    "# # first get the loss and the weights, using current guesses\n",
    "# RphiI = transform_image(xI,I,xv,v,A,xJ)    \n",
    "# rloss, W_robust_loss = robust_loss(RphiI,xJ,J,W,c, return_weights=True)    \n",
    "\n",
    "# for it_big_loop in range(niter_big_loop):\n",
    "    \n",
    "#     if it_big_loop == 0:\n",
    "#         asquare = 4.0**2*asquare0\n",
    "#     elif it_big_loop == 20:\n",
    "#         asquare = 2.0**2*asquare0\n",
    "#     elif it_big_loop == 40:\n",
    "#         asquare = 1.0**2*asquare0\n",
    "#     asquare = asquare0\n",
    "    \n",
    "    \n",
    "#     # now register, but wait until I've estimated a reasonable atlas\n",
    "#     if it_big_loop > 0:\n",
    "#         A,v,Eregistration,Ereg = weighted_see_registration(xI,I,xJ,J,W*W_robust_loss,xv,v,A,a,p,sigmaM,sigmaR,niter_reg,epT,epL,epv,draw=5,fig=fig_reg,hfig=hfig_reg)\n",
    "#     else:\n",
    "#         Ereg = 0.0\n",
    "#     # and we want to add Ereg to our loss\n",
    "    \n",
    "#     # now get jacobians\n",
    "#     Wdetjac = detjac(xv,v)\n",
    "    \n",
    "#     # now update atlas\n",
    "#     phiiRiJ = inverse_transform_image(xJ,J,xv,v,A,xI,padding_mode='border',mode='nearest')\n",
    "#     phiiRiW = inverse_transform_image(xJ,W[None]*W_robust_loss,xv,v,A,xI,padding_mode='zeros',mode='nearest')[0]    \n",
    "#     Wdetjacs = interp(xv,Wdetjac[None],XI)[0]\n",
    "#     I,Eat,ERat = atlas_from_aligned_slices_and_weights(xI,I,phiiRiJ,phiiRiW*Wdetjacs,asquare,niter=niter_atlas,fig=fig_at_estimate,hfig=hfig_at_estimate,draw=True,anisotropy_factor=anisotropy_factor)\n",
    "#     # and we want to add ERat to the loss\n",
    "    \n",
    "#     # get the loss and the weights, using current guesses\n",
    "#     RphiI = transform_image(xI,I,xv,v,A,xJ)    \n",
    "#     rloss, W_robust_loss = robust_loss(RphiI,xJ,J,W,c, return_weights=True)    \n",
    "#     # this is the loss we want to report, it's the loss with the current parameters\n",
    "    \n",
    "#     ax_at[0].cla()\n",
    "#     ax_at[0].imshow(I[:,I.shape[1]//2].permute(1,2,0))\n",
    "#     ax_at[1].cla()\n",
    "#     ax_at[1].imshow(I[:,:,I.shape[2]//2].permute(1,2,0),aspect='auto',interpolation='none')\n",
    "#     ax_at[2].cla()\n",
    "#     ax_at[2].imshow(I[:,:,:,I.shape[3]//2].permute(1,2,0),aspect='auto',interpolation='none')\n",
    "    \n",
    "    \n",
    "#     Wshow = (phiiRiW*Wdetjacs)\n",
    "#     ax_at[3].cla()\n",
    "#     ax_at[3].imshow(Wshow[I.shape[1]//2])\n",
    "#     ax_at[4].cla()\n",
    "#     ax_at[4].imshow(Wshow[:,I.shape[2]//2],aspect='auto',interpolation='none')\n",
    "#     ax_at[5].cla()\n",
    "#     ax_at[5].imshow(Wshow[:,:,I.shape[3]//2],aspect='auto',interpolation='none')\n",
    "    \n",
    "    \n",
    "#     # is this the right error? yes I think so\n",
    "#     Esave.append([rloss.item()+Ereg+ERat,rloss.item(),Ereg,ERat])\n",
    "#     ax_E[0].cla()\n",
    "#     ax_E[0].plot(Esave)\n",
    "#     ax_E[0].legend(['total', 'robust matching', 'registration reg', 'atlas reg'])\n",
    "    \n",
    "#     hfig_at.update(fig_at)\n",
    "#     hfig_E.update(fig_E)\n",
    "    \n",
    "#     #print(rloss.item() + Ereg + ERat)\n",
    "    \n",
    "#     fig_at_estimate.savefig(f'atlas_{it_big_loop:06d}.png')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ac6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isave = I # we had saved this for a comparison in the paper, not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0717520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this cell should be the main function\n",
    "niter_big_loop = 400\n",
    "niter_reg = 5\n",
    "niter_atlas = 5\n",
    "asquare = 0.25**2\n",
    "asquare0=0.25**2\n",
    "asquare0 = 3.5**2\n",
    "anisotropy_factor = 0.1**2\n",
    "\n",
    "epT = 1e-2*2*2*0\n",
    "epL = 1e-6*2*2*0\n",
    "epv = 1e1*2\n",
    "epv = 1e3\n",
    "epv = 1e2*5\n",
    "c = 1.0 # bigger c means less robustness\n",
    "c = 2.0\n",
    "\n",
    "sigmaM = 1.0 # this should always be 1\n",
    "sigmaR = 1e5 # should be smaller\n",
    "sigmaR = 1e4\n",
    "sigmaR = 2e2\n",
    "sigmaR = 5e2\n",
    "a = 8.0 # was 10\n",
    "a = 6.0\n",
    "\n",
    "\n",
    "fig_at,ax_at = plt.subplots(2,3)\n",
    "ax_at = ax_at.ravel()\n",
    "hfig_at = display(fig_at,display_id=True)\n",
    "\n",
    "fig_at_estimate = plt.figure()\n",
    "hfig_at_estimate = display(fig_at_estimate,display_id=True)\n",
    "fig_reg = plt.figure()\n",
    "hfig_reg = display(fig_reg,display_id=True)\n",
    "fig_E,ax_E = plt.subplots(1,1)\n",
    "if isinstance(ax_E,np.ndarray):\n",
    "    ax_E = ax_E.ravel()\n",
    "else:\n",
    "    ax_E = [ax_E]\n",
    "hfig_E = display(fig_E,display_id=True)\n",
    "# we want xI bigger than xJ so ther are no boundary issues\n",
    "bigger = 20\n",
    "x2dI = [torch.arange(n+bigger,dtype=dtype)*down - (n+bigger-1)*down/2 for n in nJ[1:]]\n",
    "xI = [torch.arange(nJ[0],dtype=dtype)-(nJ[0]-1)/2,x2dI[0],x2dI[1]]\n",
    "XI = torch.stack(torch.meshgrid(xI,indexing='ij'),-1)\n",
    "\n",
    "# this is the loss we want to report, not WSEE loss\n",
    "Esave = []\n",
    "v = torch.zeros_like(v)\n",
    "A = torch.eye(3)\n",
    "A = A[None].repeat(nJ[0],1,1)\n",
    "\n",
    "\n",
    "# initialize with mean\n",
    "I = torch.zeros((J.shape[0],XI.shape[0],XI.shape[1],XI.shape[2])) + (torch.sum(J*W,dim=(1,2,3))/torch.sum(W,dim=(0,1,2)))[...,None,None,None]    \n",
    "# first get the loss and the weights, using current guesses\n",
    "RphiI = transform_image(xI,I,xv,v,A,xJ)    \n",
    "rloss, W_robust_loss = robust_loss(RphiI,xJ,J,W,c, return_weights=True)    \n",
    "\n",
    "for it_big_loop in range(niter_big_loop):\n",
    "    \n",
    "    if it_big_loop == 0:\n",
    "        asquare = 4.0**2*asquare0\n",
    "    elif it_big_loop == 20:\n",
    "        asquare = 2.0**2*asquare0\n",
    "    elif it_big_loop == 40:\n",
    "        asquare = 1.0**2*asquare0\n",
    "    asquare = asquare0\n",
    "    \n",
    "    \n",
    "    # now register, but wait until I've estimated a reasonable atlas\n",
    "    if it_big_loop > 0:\n",
    "        A,v,Eregistration,Ereg = weighted_see_registration(xI,I,xJ,J,W*W_robust_loss,xv,v,A,a,p,sigmaM,sigmaR,niter_reg,epT,epL,epv,draw=5,fig=fig_reg,hfig=hfig_reg)\n",
    "    else:\n",
    "        Ereg = 0.0\n",
    "    # and we want to add Ereg to our loss\n",
    "    \n",
    "    # now get jacobians\n",
    "    Wdetjac = detjac(xv,v)\n",
    "    \n",
    "    # now update atlas\n",
    "    phiiRiJ = inverse_transform_image(xJ,J,xv,v,A,xI,padding_mode='border',mode='nearest')\n",
    "    phiiRiW = inverse_transform_image(xJ,W[None]*W_robust_loss,xv,v,A,xI,padding_mode='zeros',mode='nearest')[0]    \n",
    "    Wdetjacs = interp(xv,Wdetjac[None],XI)[0]\n",
    "    I,Eat,ERat = atlas_from_aligned_slices_and_weights(xI,I,phiiRiJ,phiiRiW*Wdetjacs,asquare,niter=niter_atlas,fig=fig_at_estimate,hfig=hfig_at_estimate,draw=True,anisotropy_factor=anisotropy_factor)\n",
    "    # and we want to add ERat to the loss\n",
    "    \n",
    "    # get the loss and the weights, using current guesses\n",
    "    RphiI = transform_image(xI,I,xv,v,A,xJ)    \n",
    "    rloss, W_robust_loss = robust_loss(RphiI,xJ,J,W,c, return_weights=True)    \n",
    "    # this is the loss we want to report, it's the loss with the current parameters\n",
    "    \n",
    "    ax_at[0].cla()\n",
    "    ax_at[0].imshow(I[:,I.shape[1]//2].permute(1,2,0))\n",
    "    ax_at[1].cla()\n",
    "    ax_at[1].imshow(I[:,:,I.shape[2]//2].permute(1,2,0),aspect='auto',interpolation='none')\n",
    "    ax_at[2].cla()\n",
    "    ax_at[2].imshow(I[:,:,:,I.shape[3]//2].permute(1,2,0),aspect='auto',interpolation='none')\n",
    "    \n",
    "    \n",
    "    Wshow = (phiiRiW*Wdetjacs)\n",
    "    ax_at[3].cla()\n",
    "    ax_at[3].imshow(Wshow[I.shape[1]//2])\n",
    "    ax_at[4].cla()\n",
    "    ax_at[4].imshow(Wshow[:,I.shape[2]//2],aspect='auto',interpolation='none')\n",
    "    ax_at[5].cla()\n",
    "    ax_at[5].imshow(Wshow[:,:,I.shape[3]//2],aspect='auto',interpolation='none')\n",
    "    \n",
    "    \n",
    "    # is this the right error? yes I think so\n",
    "    Esave.append([rloss.item()+Ereg+ERat,rloss.item(),Ereg,ERat])\n",
    "    ax_E[0].cla()\n",
    "    ax_E[0].plot(Esave)\n",
    "    ax_E[0].legend(['total', 'robust matching', 'registration reg', 'atlas reg'])\n",
    "    \n",
    "    hfig_at.update(fig_at)\n",
    "    hfig_E.update(fig_E)\n",
    "    \n",
    "    #print(rloss.item() + Ereg + ERat)\n",
    "    \n",
    "    fig_at_estimate.savefig(f'atlas_{it_big_loop:06d}.png')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e4bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will need to decide what the outputs are and how they are saved\n",
    "# I suggest just npy or npz files for everything\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf # end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3695f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "phiiRiJ = inverse_transform_image(xJ,J,xv,v,A,xI,padding_mode='border',mode='bilinear')\n",
    "phiiRiJ0 = inverse_transform_image(xJ,J,xv,v*0,A,xI,padding_mode='border',mode='bilinear')\n",
    "\n",
    "phiiRiJ = inverse_transform_image(xJ,J,xv,v,A,xI,padding_mode='border',mode='nearest')\n",
    "phiiRiJ0 = inverse_transform_image(xJ,J,xv,v*0,A,xI,padding_mode='border',mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(torch.abs(phiiRiJ - phiiRiJ0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0389a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,2)\n",
    "ax = ax.ravel()\n",
    "phiiRiJ0_ = phiiRiJ0.mean((0,1))\n",
    "phiiRiJ_ = phiiRiJ.mean((0,1))\n",
    "ax[0].imshow(phiiRiJ0_)\n",
    "ax[1].imshow(phiiRiJ_)\n",
    "ax[2].plot(phiiRiJ0[0,phiiRiJ0.shape[1]//2,phiiRiJ0_.shape[0]//2],label='slice')\n",
    "ax[2].plot(phiiRiJ0_[phiiRiJ0_.shape[0]//2],label='init')\n",
    "ax[2].plot(phiiRiJ_[phiiRiJ_.shape[0]//2],label='final')\n",
    "ax[2].legend()\n",
    "ax[3].plot(phiiRiJ0[0,phiiRiJ0.shape[1]//2,:,phiiRiJ0_.shape[1]//2],label='slice')\n",
    "ax[3].plot(phiiRiJ0_[:,phiiRiJ0_.shape[1]//2],label='init')\n",
    "ax[3].plot(phiiRiJ_[:,phiiRiJ_.shape[1]//2],label='final')\n",
    "ax[3].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e96ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sl = (slice(10,-10),slice(10,-10))\n",
    "ps0 = np.mean(np.abs(np.fft.fftn(phiiRiJ0_[sl],axes=(-1,)))**2,-2)\n",
    "ps0 = ps0 - np.abs(np.mean(np.fft.fftn(phiiRiJ0_[sl],axes=(-1,)),-2))**2\n",
    "ps = np.mean(np.abs(np.fft.fftn(phiiRiJ_[sl],axes=(-1,)))**2,-2)\n",
    "ps = ps - np.abs(np.mean(np.fft.fftn(phiiRiJ_[sl],axes=(-1,)),-2))**2\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.fft.fftshift(ps0/ps0[0]),label='orig')\n",
    "ax.plot(np.fft.fftshift(ps/ps[0]),label='final')\n",
    "ax.legend()\n",
    "ax.set_yscale('log')\n",
    "\n",
    "\n",
    "\n",
    "sl = (slice(10,-10),slice(10,-10))\n",
    "ps0 = np.mean(np.abs(np.fft.fftn(phiiRiJ0_[sl],axes=(-2,)))**2,-1)\n",
    "ps0 = ps0 - np.abs(np.mean(np.fft.fftn(phiiRiJ0_[sl],axes=(-2,)),-1))**2\n",
    "ps = np.mean(np.abs(np.fft.fftn(phiiRiJ_[sl],axes=(-2,)))**2,-1)\n",
    "ps = ps - np.abs(np.mean(np.fft.fftn(phiiRiJ_[sl],axes=(-2,)),-1))**2\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.fft.fftshift(ps0/ps0[0]),label='orig')\n",
    "ax.plot(np.fft.fftshift(ps/ps[0]),label='final')\n",
    "ax.legend()\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92e06ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4013f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = (slice(10,-10),slice(10,-10))\n",
    "# 150 factors into\n",
    "# 2 5 5 3\n",
    "# note indices 1,3 get fftd\n",
    "reshape = (30,5,30,5)\n",
    "reshape = (25,6,25,6)\n",
    "reshape = (15,10,15,10)\n",
    "\n",
    "# let's break it it up into 10x10 arrays of 15x15\n",
    "tmp = phiiRiJ0_[sl].reshape(reshape)\n",
    "# now fft along the 15x15 axes\n",
    "tmphat = np.fft.fftn(tmp,axes=(1,3))\n",
    "ps0 = np.mean(np.abs(tmphat)**2,(0,2)) - np.abs(np.mean(tmphat,(0,2)))**2\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(np.log(np.fft.fftshift(ps0/ps0[0,0])))\n",
    "\n",
    "\n",
    "tmp = phiiRiJ_[sl].reshape(reshape)\n",
    "# now fft along the 15x15 axes\n",
    "tmphat = np.fft.fftn(tmp,axes=(1,3))\n",
    "ps = np.mean(np.abs(tmphat)**2,(0,2)) - np.abs(np.mean(tmphat,(0,2)))**2\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(np.log(np.fft.fftshift(ps/ps[0,0])))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "toshow = np.fft.fftshift(np.log((ps/ps[0,0])/(ps0/ps0[0,0])))\n",
    "ax.imshow(toshow,clim=np.array([-1,1])*np.max(np.abs(toshow)))\n",
    "\n",
    "# what if we plot as a function of r\n",
    "xf = np.arange(toshow.shape[0])\n",
    "if len(xf)%2:\n",
    "    # odd\n",
    "    xf -= (len(xf)-1)//2\n",
    "else:\n",
    "    # even\n",
    "    xf -= (len(xf))//2\n",
    "R2 = np.sum(np.stack(np.meshgrid(xf,xf,indexing='ij'))**2,0)\n",
    "rs,inds = np.unique(R2,return_inverse=True)\n",
    "tmp = phiiRiJ0_[sl].reshape(reshape)\n",
    "tmphat = np.fft.fftn(tmp,axes=(1,3))\n",
    "\n",
    "ps0_ = []\n",
    "for ri in rs:\n",
    "    mu2 = np.abs(np.mean(np.mean(np.fft.fftshift(tmphat),(0,2))[R2 == ri]) )**2\n",
    "    ss = np.mean(np.mean(np.abs(np.fft.fftshift(tmphat))**2,(0,2))[R2 == ri])\n",
    "    ps0_.append( ss - mu2)\n",
    "\n",
    "tmp = phiiRiJ_[sl].reshape(reshape)\n",
    "tmphat = np.fft.fftn(tmp,axes=(1,3))\n",
    "\n",
    "ps_ = []\n",
    "for ri in rs:\n",
    "    mu2 = np.abs(np.mean(np.mean(np.fft.fftshift(tmphat),(0,2))[R2 == ri]) )**2\n",
    "    ss = np.mean(np.mean(np.abs(np.fft.fftshift(tmphat))**2,(0,2))[R2 == ri])\n",
    "    ps_.append( ss - mu2)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.sqrt(rs),ps0_)\n",
    "ax.plot(np.sqrt(rs),ps_)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.sqrt(rs),np.array(ps_)/np.array(ps0_))\n",
    "ax.set_yscale('log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps0_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmphat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a4615",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad220713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc3d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs[inds].reshape(R2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d40dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.imshow(phiiRiJ[0,phiiRiJ.shape[1]//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068dcc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is a remaining artifact I believe\n",
    "# where the images have some edge effect\n",
    "# maybe where they are next to black bu tweights are not quite right\n",
    "# i remove this by doing nearest interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641daf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "phiiRiJ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ind = 10\n",
    "ax.imshow( J[:,ind].permute(1,2,0) +  W[ind,...,None]*torch.tensor([1,0,0],dtype=dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bfa150",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_robust_loss.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.hist(W_robust_loss.ravel().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phiiRiW.requires_grad,Wdetjacs.requires_grad,Wdetjac.requires_grad,v.requires_grad,XI.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f50923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b556fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wdetjac = detjac(xv,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d680f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot0=plt.imshow(torch.mean(torch.mean(J,dim=1),dim=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a67b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "averageofJ=torch.mean(torch.mean(cropRiJ,dim=1),dim=0)\n",
    "averageofI=torch.mean(torch.mean(cropI,dim=1),dim=0)\n",
    "plot1=plt.imshow(averageofJ)\n",
    "plt.show()\n",
    "plot2=plt.imshow(averageofI)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09df116",
   "metadata": {},
   "outputs": [],
   "source": [
    "Average=torch.mean(torch.mean(J,dim=1),dim=0)\n",
    "grad=torch.sum(torch.gradient(Average)[0]**2+torch.gradient(Average)[1]**2)\n",
    "gradphiJ=torch.sum(torch.gradient(averageofJ)[0]**2+torch.gradient(averageofJ)[1]**2)\n",
    "gradI=torch.sum(torch.gradient(averageofI)[0]**2+torch.gradient(averageofI)[1]**2)\n",
    "print(grad)\n",
    "print(gradphiJ)\n",
    "print(gradI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b261fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gy, gx = torch.gradient(averageofI)\n",
    "gnorm = torch.sqrt(gx**2 + gy**2)\n",
    "sharpness = torch.mean(gnorm)\n",
    "gy1, gx1 = np.gradient(Average)\n",
    "gnorm1 = np.sqrt(gx1**2 + gy1**2)\n",
    "sharpnessA = np.average(gnorm1)\n",
    "gy2, gx2 = np.gradient(averageofJ)\n",
    "gnorm2 = np.sqrt(gx2**2 + gy2**2)\n",
    "sharpness2 = np.average(gnorm2)\n",
    "print(sharpnessA)\n",
    "print(sharpness)\n",
    "print(sharpness2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd1922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1=plt.imshow(J[0,I.shape[1]//2,:,:])\n",
    "plt.show()\n",
    "plot2=plt.imshow(J[0,:,I.shape[2]//2])\n",
    "plt.show()\n",
    "plot3=plt.imshow(J[0,:,:,I.shape[3]//2])\n",
    "plt.show()\n",
    "plot4=plt.imshow(I[0,I.shape[1]//2,:,:])\n",
    "plt.show()\n",
    "plot5=plt.imshow(I[0,:,I.shape[2]//2])\n",
    "plt.show()\n",
    "plot6=plt.imshow(I[0,:,:,I.shape[3]//2])\n",
    "plt.show()\n",
    "plot7=plt.imshow(Wshow[I.shape[1]//2])\n",
    "plt.show()\n",
    "plot8=plt.imshow(Wshow[:,I.shape[2]//2])\n",
    "plt.show()\n",
    "plot9=plt.imshow(Wshow[:,:,I.shape[3]//2])\n",
    "plt.show()\n",
    "plot10=plt.imshow(phiiRiJ[0,I.shape[1]//2])\n",
    "plt.show()\n",
    "plot11=plt.imshow(phiiRiJ[0,:,I.shape[2]//2])\n",
    "plt.show()\n",
    "plot12=plt.imshow(phiiRiJ[0,:,:,I.shape[3]//2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f14665",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropI=I[:,:,10:160, 10:160].clone().detach()\n",
    "cropW=Wshow[:,10:160, 10:160].clone().detach()\n",
    "cropRiJ=phiiRiJ[:,:,10:160, 10:160].clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplot_mosaic([['left', 'upper right'],\n",
    "                     ['left', 'lower right']],\n",
    "                              figsize=(5.5, 2.75), layout=\"constrained\")\n",
    "\n",
    "\n",
    "\n",
    "ax['left'].set_title('x-y plane view' )\n",
    "ax['left'].imshow(cropI[0,J.shape[1]//2,:,:], aspect='auto', interpolation='none')\n",
    "\n",
    "\n",
    "\n",
    "ax['upper right'].set_title('y-x plane view')\n",
    "ax['upper right'].imshow(cropI[0,:,J.shape[2]//2], aspect='auto', interpolation='none')\n",
    "\n",
    "\n",
    "ax['lower right'].set_title('x-z plane view')\n",
    "ax['lower right'].imshow(cropI[0,:,:,J.shape[3]//2], aspect='auto', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplot_mosaic([['left', 'upper right'],\n",
    "                     ['left', 'lower right']],\n",
    "                              figsize=(5.5, 2.75), layout=\"constrained\")\n",
    "\n",
    "\n",
    "\n",
    "ax['left'].set_title('x-y plane view' )\n",
    "ax['left'].imshow(cropW[J.shape[1]//2], aspect='auto', interpolation='none')\n",
    "\n",
    "\n",
    "\n",
    "ax['upper right'].set_title('y-x plane view')\n",
    "ax['upper right'].imshow(cropW[:,J.shape[2]//2], aspect='auto', interpolation='none')\n",
    "\n",
    "\n",
    "ax['lower right'].set_title('x-z plane view')\n",
    "ax['lower right'].imshow(cropW[:,:,J.shape[3]//2], aspect='auto', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplot_mosaic([['left', 'upper right'],\n",
    "                     ['left', 'lower right']],\n",
    "                              figsize=(5.5, 2.75), layout=\"constrained\")\n",
    "\n",
    "\n",
    "\n",
    "ax['left'].set_title('x-y plane view' )\n",
    "ax['left'].imshow(cropRiJ[0,J.shape[1]//2,:,:], aspect='auto', interpolation='none')\n",
    "\n",
    "\n",
    "\n",
    "ax['upper right'].set_title('y-x plane view')\n",
    "ax['upper right'].imshow(cropRiJ[0,:,J.shape[2]//2], aspect='auto', interpolation='none')\n",
    "\n",
    "\n",
    "ax['lower right'].set_title('x-z plane view')\n",
    "ax['lower right'].imshow(cropRiJ[0,:,:,J.shape[3]//2], aspect='auto', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5e114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
